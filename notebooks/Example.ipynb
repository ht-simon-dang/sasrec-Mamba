{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, ModelSummary\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.datasets import (CausalLMDataset, CausalLMPredictionDataset, MaskedLMDataset,\n",
    "                          MaskedLMPredictionDataset, PaddingCollateFn)\n",
    "from src.metrics import compute_metrics\n",
    "from src.models import RNN, BERT4Rec, SASRec\n",
    "from src.modules import SeqRec, SeqRecWithSampling\n",
    "from src.postprocess import preds2recs\n",
    "from src.preprocess import add_time_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for SASRec\n",
    "with initialize(version_base=None, config_path=\"../src/configs/\"):\n",
    "    config = compose(config_name=\"SASRec\")\n",
    "\n",
    "# # for BERT4Rec\n",
    "# with initialize(version_base=None, config_path=\"../src/configs/\"):\n",
    "#     config = compose(config_name=\"BERT4Rec\")\n",
    "\n",
    "# # for GRU4Rec\n",
    "# with initialize(version_base=None, config_path=\"../src/configs/\"):\n",
    "#     config = compose(config_name=\"RNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OmegaConf.set_struct(config, False)\n",
    "\n",
    "config.dataset.max_length = 200\n",
    "\n",
    "# # for training with negative sampling\n",
    "# config.dataset.num_negatives = 1000\n",
    "\n",
    "# # for original SASRec training with BCE loss and 1 negative example\n",
    "# config.seqrec_module.loss = 'bce'\n",
    "# config.dataset.num_negatives = 1\n",
    "# config.dataset.full_negative_sampling = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda_visible_devices: 0\n",
      "data_path: ../data/ml-1m.txt\n",
      "dataset:\n",
      "  max_length: 200\n",
      "  full_negative_sampling: false\n",
      "dataloader:\n",
      "  batch_size: 128\n",
      "  test_batch_size: 256\n",
      "  num_workers: 8\n",
      "  validation_size: 10000\n",
      "model: SASRec\n",
      "model_params:\n",
      "  maxlen: 200\n",
      "  hidden_units: 64\n",
      "  num_blocks: 2\n",
      "  num_heads: 1\n",
      "  dropout_rate: 0.1\n",
      "seqrec_module:\n",
      "  lr: 0.001\n",
      "  predict_top_k: 10\n",
      "  filter_seen: true\n",
      "trainer_params:\n",
      "  max_epochs: 100\n",
      "patience: 10\n",
      "sampled_metrics: false\n",
      "top_k_metrics:\n",
      "- 10\n",
      "- 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999611, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>time_idx_reversed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  time_idx  time_idx_reversed\n",
       "0        1        1         0                 78\n",
       "1        1        2         1                 77\n",
       "2        1        3         2                 76\n",
       "3        1        4         3                 75\n",
       "4        1        5         4                 74"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(config.data_path, sep=' ', header=None, names=['user_id', 'item_id'])\n",
    "data = add_time_idx(data, sort=False)\n",
    "\n",
    "# index 1 is used for masking value\n",
    "if config.model == 'BERT4Rec':\n",
    "    data.item_id += 1\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.time_idx_reversed >= 2]\n",
    "validation = data[data.time_idx_reversed == 1]\n",
    "validation_full = data[data.time_idx_reversed >= 1]\n",
    "test = data[data.time_idx_reversed == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = config.dataloader.validation_size\n",
    "validation_users = validation_full.user_id.unique()\n",
    "if validation_size and (validation_size < len(validation_users)):\n",
    "    validation_users = np.random.choice(validation_users, size=validation_size, replace=False)\n",
    "\n",
    "if config.model in ['SASRec', 'RNN']:\n",
    "    train_dataset = CausalLMDataset(train, **config['dataset'])\n",
    "    eval_dataset = CausalLMPredictionDataset(\n",
    "        validation_full[validation_full.user_id.isin(validation_users)],\n",
    "        max_length=config.dataset.max_length, validation_mode=True)\n",
    "elif config.model == 'BERT4Rec':\n",
    "    train_dataset = MaskedLMDataset(train, **config['dataset'])\n",
    "    eval_dataset = MaskedLMPredictionDataset(\n",
    "        validation_full[validation_full.user_id.isin(validation_users)],\n",
    "        max_length=config.dataset.max_length, validation_mode=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, shuffle=True,\n",
    "    collate_fn=PaddingCollateFn(),\n",
    "    batch_size=config.dataloader.batch_size,\n",
    "    num_workers=config.dataloader.num_workers)\n",
    "eval_loader = DataLoader(\n",
    "    eval_dataset, shuffle=False,\n",
    "    collate_fn=PaddingCollateFn(),\n",
    "    batch_size=config.dataloader.test_batch_size,\n",
    "    num_workers=config.dataloader.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 200])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_count = data.item_id.max()\n",
    "\n",
    "if hasattr(config.dataset, 'num_negatives') and config.dataset.num_negatives:\n",
    "    add_head = False\n",
    "else:\n",
    "    add_head = True\n",
    "\n",
    "if config.model == 'SASRec':\n",
    "    model = SASRec(item_num=item_count, add_head=add_head, **config.model_params)\n",
    "if config.model == 'BERT4Rec':\n",
    "    model = BERT4Rec(vocab_size=item_count + 1, add_head=add_head,\n",
    "                     bert_config=config.model_params)\n",
    "elif config.model == 'RNN':\n",
    "    model = RNN(vocab_size=item_count + 1, add_head=add_head,\n",
    "                rnn_config=config.model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 200, 3417])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(batch['input_ids'], batch['attention_mask'])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Trainer.__init__() got an unexpected keyword argument 'gpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m checkpoint = ModelCheckpoint(save_top_k=\u001b[32m1\u001b[39m, monitor=\u001b[33m\"\u001b[39m\u001b[33mval_ndcg\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m                              mode=\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m, save_weights_only=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     11\u001b[39m callbacks=[early_stopping, model_summary, checkpoint]\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m trainer = \u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_checkpointing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mgpus\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrainer_params\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m trainer.fit(model=seqrec_module,\n\u001b[32m     17\u001b[39m             train_dataloaders=train_loader,\n\u001b[32m     18\u001b[39m             val_dataloaders=eval_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/py312/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py:70\u001b[39m, in \u001b[36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m kwargs = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables.items()) + \u001b[38;5;28mlist\u001b[39m(kwargs.items()))\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Trainer.__init__() got an unexpected keyword argument 'gpus'"
     ]
    }
   ],
   "source": [
    "if hasattr(config.dataset, 'num_negatives') and config.dataset.num_negatives:\n",
    "    seqrec_module = SeqRecWithSampling(model, **config['seqrec_module'])\n",
    "else:\n",
    "    seqrec_module = SeqRec(model, **config['seqrec_module'])\n",
    "    \n",
    "early_stopping = EarlyStopping(monitor=\"val_ndcg\", mode=\"max\",\n",
    "                               patience=config.patience, verbose=False)\n",
    "model_summary = ModelSummary(max_depth=2)\n",
    "checkpoint = ModelCheckpoint(save_top_k=1, monitor=\"val_ndcg\",\n",
    "                             mode=\"max\", save_weights_only=True)\n",
    "callbacks=[early_stopping, model_summary, checkpoint]\n",
    "\n",
    "trainer = pl.Trainer(callbacks=callbacks, enable_checkpointing=True,\n",
    "                     gpus=1, **config['trainer_params'])\n",
    "\n",
    "trainer.fit(model=seqrec_module,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqrec_module.load_state_dict(torch.load(checkpoint.best_model_path)['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12729178b23443be93adf5ef1b606667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 48it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>737</td>\n",
       "      <td>7.598266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>663</td>\n",
       "      <td>7.248270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>7.237531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>745</td>\n",
       "      <td>7.148354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>7.065181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  prediction\n",
       "0        1      737    7.598266\n",
       "1        1      663    7.248270\n",
       "2        1      102    7.237531\n",
       "3        1      745    7.148354\n",
       "4        1     1125    7.065181"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if config.model in ['SASRec', 'RNN']:\n",
    "    predict_dataset = CausalLMPredictionDataset(train, max_length=config.dataset.max_length)\n",
    "elif config.model  == 'BERT4Rec':\n",
    "    predict_dataset = MaskedLMPredictionDataset(train, max_length=config.dataset.max_length)\n",
    "\n",
    "predict_loader = DataLoader(\n",
    "        predict_dataset, shuffle=False,\n",
    "        collate_fn=PaddingCollateFn(),\n",
    "        batch_size=config.dataloader.test_batch_size,\n",
    "        num_workers=config.dataloader.num_workers)\n",
    "\n",
    "seqrec_module.predict_top_k = max(config.top_k_metrics)\n",
    "preds = trainer.predict(model=seqrec_module, dataloaders=predict_loader)\n",
    "\n",
    "recs = preds2recs(preds)\n",
    "print(recs.shape)\n",
    "recs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  10\n",
      "{'ndcg@10': 0.18906012825101937, 'hit_rate@10': 0.33228476821192054, 'mrr@10': 0.14530563439503838}\n",
      "k =  100\n",
      "{'ndcg@100': 0.2657238370955717, 'hit_rate@100': 0.7066225165562914, 'mrr@100': 0.15960866987332128}\n"
     ]
    }
   ],
   "source": [
    "for k in config.top_k_metrics:\n",
    "    metrics_val = compute_metrics(validation, recs, k=k)\n",
    "    print('k = ', k)\n",
    "    print(metrics_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77ef7bd1e68434c84610c0553532638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 48it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>872</td>\n",
       "      <td>6.629054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>667</td>\n",
       "      <td>6.363072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>745</td>\n",
       "      <td>6.264328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>679</td>\n",
       "      <td>6.156502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>737</td>\n",
       "      <td>6.107877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  prediction\n",
       "0        1      872    6.629054\n",
       "1        1      667    6.363072\n",
       "2        1      745    6.264328\n",
       "3        1      679    6.156502\n",
       "4        1      737    6.107877"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if config.model in ['SASRec', 'RNN']:\n",
    "    test_predict_dataset = CausalLMPredictionDataset(validation_full, max_length=config.dataset.max_length)\n",
    "elif config.model  == 'BERT4Rec':\n",
    "    test_predict_dataset = MaskedLMPredictionDataset(validation_full, max_length=config.dataset.max_length)\n",
    "    \n",
    "test_predict_loader = DataLoader(\n",
    "        test_predict_dataset, shuffle=False,\n",
    "        collate_fn=PaddingCollateFn(),\n",
    "        batch_size=config.dataloader.test_batch_size,\n",
    "        num_workers=config.dataloader.num_workers)\n",
    "\n",
    "seqrec_module.predict_top_k = max(config.top_k_metrics)\n",
    "preds_test = trainer.predict(model=seqrec_module, dataloaders=test_predict_loader)\n",
    "\n",
    "recs_test = preds2recs(preds_test)\n",
    "print(recs_test.shape)\n",
    "recs_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  10\n",
      "{'ndcg@10': 0.18250363127629773, 'hit_rate@10': 0.31473509933774835, 'mrr@10': 0.14229160096709764}\n",
      "k =  100\n",
      "{'ndcg@100': 0.25577861370312055, 'hit_rate@100': 0.6736754966887417, 'mrr@100': 0.15588159170341734}\n"
     ]
    }
   ],
   "source": [
    "for k in config.top_k_metrics:\n",
    "    metrics_test = compute_metrics(test, recs_test, k=k)\n",
    "    print('k = ', k)\n",
    "    print(metrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
